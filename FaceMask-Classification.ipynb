{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rescale=1./255,\n        validation_split=0.2,\n        shear_range=0,\n        zoom_range=0,\n        horizontal_flip=False,\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1)  # randomly shift images vertically (fraction of total height))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = datagen.flow_from_directory(\n    '../input/face-mask-detection/dataset', \n    subset='training',\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)\n\nval_generator = datagen.flow_from_directory(\n    '../input/face-mask-detection/dataset',\n    subset='validation',\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg=tensorflow.keras.applications.VGG16(include_top=False, input_shape=(224,224,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet=tensorflow.keras.applications.ResNet50(include_top=False, input_shape=(224,224,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception=tensorflow.keras.applications.InceptionV3(include_top=False, input_shape=(224,224,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''for layer in vgg.layers:\n    layer.trainable=False'''\n\nfor layer in resnet.layers:\n    layer.trainable=False\n\n'''for layer in inception.layers:\n    layer.trainable=False'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vgg.summary()\nresnet.summary()\n#inception.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flatten_layer= Flatten()(resnet.output)\nfinal_layer= Dense(2,activation='softmax')(flatten_layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#assemble model\nmodel= Model(inputs=resnet.input, outputs= final_layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate_generator(generator=val_generator,steps=len(val_generator))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mask_nomask(filepath):\n    img0=cv2.imread(filepath)\n    img0=cv2.resize(img0,(224,224))/255\n    class_code=model.predict(img0.reshape(1,224,224,3)).argmax()\n    return 'with mask' if class_code==0 else 'without mask'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/face-mask-detection/dataset/with_mask/image_123.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/face-mask-detection/dataset/without_mask/image_103.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/face-mask-detection/dataset/without_mask/image_174.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/myownimages/IMG-20210417-WA0005.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/myownimages/IMG-20210417-WA0006.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/myownimages/IMG20210308152528.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/myimage/IMG20200915124631.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mask_nomask('../input/myimage/IMG20210123131749.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}